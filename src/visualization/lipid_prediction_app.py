"""
å¾®è—»è„‚è´¨å«é‡é¢„æµ‹ç³»ç»Ÿ
åŸºäºè®­ç»ƒå¥½çš„SVMæ¨¡å‹çš„å¯è§†åŒ–é¢„æµ‹ç•Œé¢
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.preprocessing import StandardScaler

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¾®è—»è„‚è´¨å«é‡é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_resource
def load_model_and_info():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œç›¸å…³ä¿¡æ¯"""
    try:
        import os

        # è·å–å½“å‰è„šæœ¬çš„ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        project_root = os.path.dirname(os.path.dirname(current_dir))

        # æ„å»ºæ–‡ä»¶è·¯å¾„
        model_path = os.path.join(project_root, "results", "model_training", "trained_svm_model.pkl")
        feature_path = os.path.join(project_root, "results", "model_training", "model_features.csv")
        info_path = os.path.join(project_root, "results", "model_training", "model_info.csv")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            st.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return None, None, None

        # åŠ è½½æ¨¡å‹
        model = joblib.load(model_path)

        # åŠ è½½ç‰¹å¾ä¿¡æ¯
        feature_info = pd.read_csv(feature_path)
        feature_names = feature_info['feature_name'].tolist()

        # åŠ è½½æ¨¡å‹ä¿¡æ¯
        model_info = pd.read_csv(info_path)

        return model, feature_names, model_info
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None, None, None

def get_feature_ranges():
    """è·å–ç‰¹å¾çš„åˆç†å–å€¼èŒƒå›´ï¼ˆåŸºäºåŸå§‹æ•°æ®ï¼‰"""
    try:
        import os

        # è·å–å½“å‰è„šæœ¬çš„ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        project_root = os.path.dirname(os.path.dirname(current_dir))

        # æ„å»ºåŸå§‹æ•°æ®è·¯å¾„
        raw_data_path = os.path.join(project_root, "data", "raw_analysis", "æ•°æ®.xlsx")

        # åŠ è½½åŸå§‹æ•°æ®æ¥è·å–ç‰¹å¾èŒƒå›´
        raw_data = pd.read_excel(raw_data_path)

        feature_ranges = {
            'DO': (raw_data['DO'].min(), raw_data['DO'].max()),
            'electrical conductivity': (raw_data['electrical conductivity'].min(), raw_data['electrical conductivity'].max()),
            'nitrate nitrogen': (raw_data['nitrate nitrogen'].min(), raw_data['nitrate nitrogen'].max()),
            'TP': (raw_data['TP'].min(), raw_data['TP'].max()),
            'Dry cell weight': (raw_data['Dry cell weight'].min(), raw_data['Dry cell weight'].max()),
            'protein(%)': (raw_data['protein(%)'].min(), raw_data['protein(%)'].max()),
            'C(%)': (raw_data['C(%)'].min(), raw_data['C(%)'].max()),
            'H(%)': (raw_data['H(%)'].min(), raw_data['H(%)'].max()),
            'O(%)': (raw_data['O(%)'].min(), raw_data['O(%)'].max()),
            'N conversion rate(%)': (raw_data['N conversion rate(%)'].min(), raw_data['N conversion rate(%)'].max())
        }
        return feature_ranges
    except Exception as e:
        st.warning(f"æ— æ³•åŠ è½½åŸå§‹æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤èŒƒå›´: {e}")
        # åŸºäºå®é™…æ•°æ®çš„åˆç†èŒƒå›´
        return {
            'DO': (7.0, 21.0),
            'electrical conductivity': (150.0, 900.0),
            'nitrate nitrogen': (0.0, 13.0),
            'TP': (0.0, 7.0),
            'Dry cell weight': (4.0, 112.0),
            'protein(%)': (0.0, 20.0),
            'C(%)': (20.0, 54.0),
            'H(%)': (3.0, 13.0),
            'O(%)': (24.0, 42.0),
            'N conversion rate(%)': (0.0, 1.0)
        }

def create_input_form(feature_names, feature_ranges):
    """åˆ›å»ºè¾“å…¥è¡¨å•"""
    st.sidebar.header("ğŸ”¬ è¾“å…¥ç‰¹å¾å‚æ•°")
    
    # ç‰¹å¾å•ä½å’Œæè¿°
    feature_descriptions = {
        'DO': ('mg/L', 'æº¶è§£æ°§æµ“åº¦'),
        'electrical conductivity': ('Î¼S/cm', 'ç”µå¯¼ç‡'),
        'nitrate nitrogen': ('mg/L', 'ç¡æ€æ°®æµ“åº¦'),
        'TP': ('mg/L', 'æ€»ç£·æµ“åº¦'),
        'Dry cell weight': ('g/L', 'å¹²ç»†èƒé‡é‡'),
        'protein(%)': ('%', 'è›‹ç™½è´¨å«é‡ç™¾åˆ†æ¯”'),
        'C(%)': ('%', 'ç¢³å…ƒç´ å«é‡ç™¾åˆ†æ¯”'),
        'H(%)': ('%', 'æ°¢å…ƒç´ å«é‡ç™¾åˆ†æ¯”'),
        'O(%)': ('%', 'æ°§å…ƒç´ å«é‡ç™¾åˆ†æ¯”'),
        'N conversion rate(%)': ('%', 'æ°®è½¬åŒ–ç‡ç™¾åˆ†æ¯”')
    }
    
    input_values = {}
    
    for feature in feature_names:
        min_val, max_val = feature_ranges.get(feature, (0.0, 100.0))
        unit, description = feature_descriptions.get(feature, ('', ''))
        
        # è®¡ç®—é»˜è®¤å€¼ï¼ˆä¸­ä½æ•°ï¼‰
        default_val = (min_val + max_val) / 2
        
        input_values[feature] = st.sidebar.number_input(
            f"{feature} ({unit})",
            min_value=float(min_val),
            max_value=float(max_val),
            value=float(default_val),
            step=0.01,
            help=description
        )
    
    return input_values

@st.cache_data
def get_standardization_params():
    """è·å–æ ‡å‡†åŒ–å‚æ•°ï¼ˆåŸºäºè®­ç»ƒæ•°æ®ï¼‰"""
    try:
        import os

        # è·å–å½“å‰è„šæœ¬çš„ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        project_root = os.path.dirname(os.path.dirname(current_dir))

        # åŠ è½½åŸå§‹æ•°æ®
        raw_data_path = os.path.join(project_root, "data", "raw_analysis", "æ•°æ®.xlsx")
        raw_data = pd.read_excel(raw_data_path)

        # è·å–ç‰¹å¾åˆ—
        feature_columns = ['DO', 'electrical conductivity', 'nitrate nitrogen', 'TP',
                          'Dry cell weight', 'protein(%)', 'C(%)', 'H(%)', 'O(%)', 'N conversion rate(%)']

        # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
        means = raw_data[feature_columns].mean()
        stds = raw_data[feature_columns].std()

        return means, stds
    except Exception as e:
        st.error(f"æ— æ³•è·å–æ ‡å‡†åŒ–å‚æ•°: {e}")
        return None, None

def standardize_input(input_values, feature_names):
    """æ ‡å‡†åŒ–è¾“å…¥æ•°æ®"""
    means, stds = get_standardization_params()

    if means is None or stds is None:
        st.error("æ— æ³•è¿›è¡Œæ•°æ®æ ‡å‡†åŒ–")
        return None

    # åˆ›å»ºDataFrame
    input_df = pd.DataFrame([input_values])

    # æ ‡å‡†åŒ–
    standardized_values = {}
    for feature in feature_names:
        if feature in means.index and feature in stds.index:
            standardized_values[feature] = (input_values[feature] - means[feature]) / stds[feature]
        else:
            standardized_values[feature] = input_values[feature]

    return standardized_values

def make_prediction(model, feature_names, input_values):
    """è¿›è¡Œé¢„æµ‹"""
    # æ ‡å‡†åŒ–è¾“å…¥æ•°æ®
    standardized_values = standardize_input(input_values, feature_names)

    if standardized_values is None:
        return None

    # å‡†å¤‡è¾“å…¥æ•°æ®
    input_data = pd.DataFrame([standardized_values])
    input_data = input_data[feature_names]  # ç¡®ä¿ç‰¹å¾é¡ºåºæ­£ç¡®

    # è¿›è¡Œé¢„æµ‹
    prediction = model.predict(input_data)[0]

    return prediction

def display_prediction_result(prediction):
    """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
    st.header("ğŸ¯ é¢„æµ‹ç»“æœ")
    
    # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            label="é¢„æµ‹è„‚è´¨å«é‡",
            value=f"{prediction:.2f}%",
            delta=None
        )
    
    with col2:
        # æ ¹æ®è„‚è´¨å«é‡ç»™å‡ºè¯„çº§
        if prediction >= 20:
            grade = "ä¼˜ç§€"
            color = "green"
        elif prediction >= 15:
            grade = "è‰¯å¥½"
            color = "blue"
        elif prediction >= 10:
            grade = "ä¸€èˆ¬"
            color = "orange"
        else:
            grade = "è¾ƒä½"
            color = "red"
        
        st.metric(
            label="è„‚è´¨å«é‡ç­‰çº§",
            value=grade,
            delta=None
        )
    
    with col3:
        # æ˜¾ç¤ºç½®ä¿¡åº¦ï¼ˆåŸºäºæ¨¡å‹æ€§èƒ½ï¼‰
        confidence = "ä¸­ç­‰"  # åŸºäºRÂ²=0.59
        st.metric(
            label="é¢„æµ‹ç½®ä¿¡åº¦",
            value=confidence,
            delta=None
        )

def create_feature_importance_chart():
    """åˆ›å»ºç‰¹å¾é‡è¦æ€§å›¾è¡¨"""
    # è¿™é‡Œå¯ä»¥åŸºäºRandomForestçš„ç‰¹å¾é‡è¦æ€§
    feature_importance = {
        'H(%)': 0.2891,
        'O(%)': 0.2016,
        'nitrate nitrogen': 0.1047,
        'DO': 0.0906,
        'Dry cell weight': 0.0666,
        'TP': 0.0550,
        'N conversion rate(%)': 0.0540,
        'electrical conductivity': 0.0484,
        'protein(%)': 0.0461,
        'C(%)': 0.0439
    }
    
    fig = px.bar(
        x=list(feature_importance.values()),
        y=list(feature_importance.keys()),
        orientation='h',
        title="ç‰¹å¾é‡è¦æ€§æ’åº",
        labels={'x': 'é‡è¦æ€§å¾—åˆ†', 'y': 'ç‰¹å¾åç§°'}
    )
    fig.update_layout(height=400)
    
    return fig

def main():
    """ä¸»å‡½æ•°"""
    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ§¬ å¾®è—»è„‚è´¨å«é‡é¢„æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    # åŠ è½½æ¨¡å‹
    model, feature_names, model_info = load_model_and_info()
    
    if model is None:
        st.error("âŒ æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼")
        return
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    with st.expander("ğŸ“Š æ¨¡å‹ä¿¡æ¯", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**æ¨¡å‹å‚æ•°:**")
            st.write(f"- æ¨¡å‹ç±»å‹: {model_info['model_type'].iloc[0]}")
            st.write(f"- æ ¸å‡½æ•°: {model_info['kernel'].iloc[0]}")
            st.write(f"- Cå‚æ•°: {model_info['C'].iloc[0]}")
            st.write(f"- Gamma: {model_info['gamma'].iloc[0]}")
        
        with col2:
            st.write("**æ¨¡å‹æ€§èƒ½:**")
            st.write(f"- è®­ç»ƒé›†RÂ²: {model_info['train_r2'].iloc[0]:.4f}")
            st.write(f"- è®­ç»ƒé›†MAE: {model_info['train_mae'].iloc[0]:.4f}")
            st.write(f"- ç‰¹å¾æ•°é‡: {model_info['n_features'].iloc[0]}")
    
    # è·å–ç‰¹å¾èŒƒå›´
    feature_ranges = get_feature_ranges()
    
    # åˆ›å»ºè¾“å…¥è¡¨å•
    input_values = create_input_form(feature_names, feature_ranges)
    
    # é¢„æµ‹æŒ‰é’®
    if st.sidebar.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
        with st.spinner("æ­£åœ¨é¢„æµ‹ä¸­..."):
            prediction = make_prediction(model, feature_names, input_values)
            
            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            display_prediction_result(prediction)
            
            # æ˜¾ç¤ºè¾“å…¥å‚æ•°
            st.subheader("ğŸ“‹ è¾“å…¥å‚æ•°")
            input_df = pd.DataFrame([input_values]).T
            input_df.columns = ['è¾“å…¥å€¼']
            st.dataframe(input_df, use_container_width=True)
    
    # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§
    st.subheader("ğŸ“ˆ ç‰¹å¾é‡è¦æ€§åˆ†æ")
    fig = create_feature_importance_chart()
    st.plotly_chart(fig, use_container_width=True)
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ### å¦‚ä½•ä½¿ç”¨æœ¬é¢„æµ‹ç³»ç»Ÿï¼š
        
        1. **è¾“å…¥å‚æ•°**: åœ¨å·¦ä¾§è¾¹æ ä¸­è¾“å…¥å„é¡¹ç‰¹å¾å‚æ•°
        2. **å‚æ•°èŒƒå›´**: æ¯ä¸ªå‚æ•°éƒ½æœ‰åˆç†çš„å–å€¼èŒƒå›´ï¼ŒåŸºäºè®­ç»ƒæ•°æ®ç¡®å®š
        3. **å¼€å§‹é¢„æµ‹**: ç‚¹å‡»"å¼€å§‹é¢„æµ‹"æŒ‰é’®è·å¾—è„‚è´¨å«é‡é¢„æµ‹ç»“æœ
        4. **ç»“æœè§£è¯»**: 
           - é¢„æµ‹å€¼ä¸ºè„‚è´¨å«é‡ç™¾åˆ†æ¯”
           - ç­‰çº§è¯„å®šï¼šä¼˜ç§€(â‰¥20%), è‰¯å¥½(15-20%), ä¸€èˆ¬(10-15%), è¾ƒä½(<10%)
        
        ### ç‰¹å¾è¯´æ˜ï¼š
        - **DO**: æº¶è§£æ°§æµ“åº¦ï¼Œå½±å“å¾®è—»çš„å‘¼å¸å’Œä»£è°¢
        - **ç”µå¯¼ç‡**: åæ˜ æ°´ä½“ä¸­ç¦»å­æµ“åº¦
        - **ç¡æ€æ°®**: é‡è¦çš„æ°®æºè¥å…»å…ƒç´ 
        - **æ€»ç£·(TP)**: é‡è¦çš„ç£·æºè¥å…»å…ƒç´ 
        - **å…ƒç´ å«é‡(C%, H%, O%)**: å¾®è—»ç»†èƒçš„å…ƒç´ ç»„æˆ
        - **è›‹ç™½è´¨å«é‡**: åæ˜ å¾®è—»çš„è¥å…»çŠ¶æ€
        """)

if __name__ == "__main__":
    main()
